{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOH7cWe+eKBeoGidW7Z2pEN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jyuill/python-gpt/blob/main/py_gpt_test_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Accessing ChatGPT in Python notebook\n",
        "\n",
        "Small example of how to set up python code in Google colab to access ChatGPT"
      ],
      "metadata": {
        "id": "BoTYm3LZuBZb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# set up required packages\n",
        "!pip install openai\n",
        "import openai\n",
        "from openai import OpenAI\n",
        "import os"
      ],
      "metadata": {
        "id": "gctzAVmx3VdZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e3318d0-467c-4aff-b935-b70dcb16ad46"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.40.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.5.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# using Google colab secrets manager to store/retrieve open ai api key\n",
        "# other options could be using .env file in the project or storing secrets in private gsheet drive that can be imported\n",
        "from google.colab import userdata\n",
        "openai_api_key = userdata.get('OpenAI_API_KEY')\n",
        "# confirm if nec\n",
        "#print(openai_api_key)"
      ],
      "metadata": {
        "id": "mjfiVFEksXrw"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get api key for use\n",
        "client = OpenAI(\n",
        "    api_key = openai_api_key\n",
        ")\n",
        "# sample chat to test\n",
        "chat_completion = client.chat.completions.create(\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Who is the reigning monarch of the United Kingdom?\",\n",
        "        }\n",
        "    ],\n",
        "    model=\"gpt-3.5-turbo\",\n",
        ")"
      ],
      "metadata": {
        "id": "B2cLWpyM4dmC"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract and print the content of the response\n",
        "#response_text = chat_completion['choices'][0]['message']['content']\n",
        "response_text = chat_completion.choices[0].message.content\n",
        "print(response_text)"
      ],
      "metadata": {
        "id": "-VRLgtH_G_BB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95aaa07b-93d2-4787-b0ab-e0f6d7b9d0c8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The reigning monarch of the United Kingdom is Queen Elizabeth II.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# function for using chat - provided by Gemini\n",
        "# select model: gpt-3.5-turbo, gpt-4, etc\n",
        "# depends on openai account access; may want to factor in cost considerations\n",
        "def chat_with_gpt(prompt, model=\"gpt-4\"):\n",
        "  \"\"\"Interacts with ChatGPT and returns the response.\n",
        "\n",
        "  Args:\n",
        "    prompt: The user's input prompt.\n",
        "    model: The ChatGPT model to use. Defaults to \"gpt-3.5-turbo\".\n",
        "\n",
        "  Returns:\n",
        "    The ChatGPT response.\n",
        "  \"\"\"\n",
        "  chat_completion = client.chat.completions.create(\n",
        "      messages=[\n",
        "          {\n",
        "              \"role\": \"user\",\n",
        "              \"content\": prompt,\n",
        "          }\n",
        "      ],\n",
        "      model=model,\n",
        "  )\n",
        "  return chat_completion.choices[0].message.content\n",
        "\n",
        "# Example usage\n",
        "user_prompt = \"Translate 'Hello world' to Spanish.\"\n",
        "response = chat_with_gpt(user_prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9FgsNmFut-E",
        "outputId": "5e159a4f-99e5-40cf-be64-da0fe04b62f5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hola mundo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_prompt = \"What is the capital of France?\"\n",
        "response = chat_with_gpt(user_prompt)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pe2zrRP4vUlF",
        "outputId": "73f26655-1c53-4272-f269-9249bde887c2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The capital of France is Paris.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get user input\n",
        "user_prompt = input(\"Enter your prompt: \")\n",
        "\n",
        "# Call the chat_with_gpt function\n",
        "response = chat_with_gpt(user_prompt)\n",
        "\n",
        "# Print the response\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjG986wLvcf6",
        "outputId": "18deaefc-b4aa-4ee1-93c9-053c6fb18345"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your prompt: what is the guitar chord structure for Bob Dylan's \"Like a Rolling Stone\"?\n",
            "Verses:\n",
            "1. C Dm Em F G  \n",
            "2. C Dm Em F G  \n",
            "3. C Dm Em F  \n",
            "4. D\n",
            "\n",
            "Chorus: \n",
            "1. C (Am/C) C  F  G\n",
            "2. C (Am/C) C  F \n",
            "\n",
            "Note: Each chord is 4 beats unless otherwise noted.\n",
            "\n",
            "This is just a general guideline and may need to be adapted based on your style of play and your specific arrangement. This also doesn't take into account any of the potential nuances, fills, or guitar solos in the original recording. Always a good idea to listen to the song to get the rhythm and the flow of the chords.\n"
          ]
        }
      ]
    }
  ]
}